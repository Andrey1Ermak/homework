{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a0bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72bd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем 2 признака и 1000 объектов\n",
    "n_features = 2\n",
    "n_objects = 1000\n",
    "\n",
    "# сгенерируем вектор истинных весов\n",
    "w_true = np.random.normal(size=(1, n_features ))\n",
    "\n",
    "# сгенерируем матрицу X, вычислим Y с добавлением случайного шума\n",
    "X = np.random.uniform(-7, 7, (n_objects, n_features))\n",
    "Y = X.dot(w_true.T) + np.random.normal(0, 0.5, size=(n_objects, 1))\n",
    "\n",
    "# возьмем нулевые начальные веса\n",
    "w = np.zeros((1, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b35a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self, eta = 0.9, max_iter = 1e4, min_weight_dist = 1e-8):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.min_weight_dist = min_weight_dist  \n",
    "        \n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]\n",
    "    \n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        return 2*delta.T.dot(X)/y_real.shape[0], np.sum(2*delta)/y_real.shape[0]    \n",
    "    \n",
    "    def _optimize(self, X, Y):\n",
    "        #оптимизация коэффициентов\n",
    "        iter_num = 0\n",
    "        weight_dist = np.inf\n",
    "        self.w = np.zeros((1, X.shape[1]))\n",
    "        self.w0=0\n",
    "        while weight_dist > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            gr_w, gr_w0=self._mserror_grad(X, Y)\n",
    "            if iter_num==0:\n",
    "                #Чтобы eta адаптировалась к порядку градиента, делим на l2 норму градиента в нуле\n",
    "                eta=self.eta/np.sqrt(np.linalg.norm(gr_w)**2+(gr_w0)**2)\n",
    "            new_w = self.w - eta * gr_w\n",
    "            new_w0= self.w0 - eta * gr_w0\n",
    "            weight_dist = np.sqrt(np.linalg.norm(new_w - self.w)**2+(new_w0 - self.w0)**2)\n",
    "            iter_num += 1\n",
    "            self.w = new_w\n",
    "            self.w0 = new_w0         \n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        self._optimize(X, Y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return (X.dot(self.w.T)+self.w0).flatten()\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        return self._mserror(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dced18b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2398047356641924"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "Y_shift=Y+shift\n",
    "lr=linear_regression()\n",
    "lr.fit(X, Y_shift)\n",
    "lr.test(X, Y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f2c02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74.17746838494357, 74.16697491064924)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift, lr.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de386334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.2325803, -0.0265373]]), array([[ 0.22630537, -0.02423686]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w, w_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d8a4a",
   "metadata": {},
   "source": [
    "Регуляризация уменьшает сложность модели для предотвращения переобучени.\n",
    "L1-регуляризация \"штрафует\" весовые значения добавлением суммы их абсолютных значений к ошибке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6eea447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self, eta = 0.9, _lambda=0.001, max_iter = 1e4, min_weight_dist = 1e-8):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.min_weight_dist = min_weight_dist\n",
    "        self._lambda = _lambda\n",
    "        \n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        reg = np.sum(self.w)**2+self.w0**2\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]+self._lambda*reg\n",
    "    \n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        reg_grad_w = self.w\n",
    "        reg_grad_w0 = 2*self.w0\n",
    "        return (2*delta.T.dot(X)/y_real.shape[0]+self._lambda*reg_grad_w,\n",
    "                np.sum(2*delta)/y_real.shape[0]+self._lambda*reg_grad_w0)\n",
    "    \n",
    "    def _optimize(self, X, Y):\n",
    "        #оптимизация коэффициентов\n",
    "        iter_num = 0\n",
    "        weight_dist = np.inf\n",
    "        self.w = np.zeros((1, X.shape[1]))\n",
    "        self.w0=0\n",
    "        while weight_dist > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            gr_w, gr_w0=self._mserror_grad(X, Y)\n",
    "            if iter_num==0:\n",
    "                #Чтобы eta адаптировалась к порядку градиента, делим на l2 норму градиента в нуле\n",
    "                eta=self.eta/np.sqrt(np.linalg.norm(gr_w)**2+(gr_w0)**2)\n",
    "            new_w = self.w - eta * gr_w\n",
    "            new_w0= self.w0 - eta * gr_w0\n",
    "            weight_dist = np.sqrt(np.linalg.norm(new_w - self.w)**2+(new_w0 - self.w0)**2)\n",
    "            iter_num += 1\n",
    "            self.w = new_w\n",
    "            self.w0 = new_w0\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        self._optimize(X, Y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return (X.dot(self.w.T)+self.w0).flatten()\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        return self._mserror(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660a5254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.74979685448449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "Y_shift=Y+shift\n",
    "lr=linear_regression()\n",
    "lr.fit(X, Y_shift)\n",
    "lr.test(X, Y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f741d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.57821559753475, 97.47024187810278)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift, lr.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6176b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.23238926, -0.02638905]]), array([[ 0.22630537, -0.02423686]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w, w_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfea0122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24930636662120587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lr.predict(X)-Y_shift.flatten())**2)/Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397b995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
