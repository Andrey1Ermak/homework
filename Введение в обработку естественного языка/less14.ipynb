{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6bea26-a233-4db7-87e7-e142f988d058",
   "metadata": {},
   "source": [
    "# Урок 14. Transfer learning\n",
    "\n",
    "Взять данные из https://www.kaggle.com/datasets/mrapplexz/bashim-quotes обучить модель GPT для генерации своих цитат\n",
    "\n",
    "Взять новостные данные из https://github.com/natasha/corus load_lenta2 нам понадобиться сам текст и заголовок обучить модель T5/ или GPT для генерации заголовков для статей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04531a6e-0bb9-4327-82ab-0e2fa620e603",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffae72e-553f-40d7-b7c4-37ebf787352f",
   "metadata": {
    "id": "sAQbiISp7Jz-"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa0e52-3aa5-4fb9-a4f8-349e229bb0d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "Laf4hlAo7KA0",
    "outputId": "b8665703-0095-4de1-c5e0-52b996ef510c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:40:51.359144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 15:40:52.264887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Ares&gt; ppdv, все юниксы очень дружелюбны.. они просто очень разборчивы в друзьях ;)</td>\n",
       "      <td>ppdv, все юниксы очень дружелюбны.. они просто очень разборчивы в друзьях ;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;томатик_рад&gt; а ты не чувствуешь красоту мира?\\n&lt;fox&gt; честно говоря, я сейчас чувствую только отсутствие http.\\n&lt;томатик_рад&gt; не туда смотришь, глянь вокруг!\\n&lt;fox&gt; как я гляну, если http не работает? :/</td>\n",
       "      <td>а ты не чувствуешь красоту мира?   честно говоря, я сейчас чувствую только отсутствие http.   не туда смотришь, глянь вокруг!   как я гляну, если http не работает? :/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                           text  \\\n",
       "id                                                                                                                                                                                                                \n",
       "1                                                                                                                           <Ares> ppdv, все юниксы очень дружелюбны.. они просто очень разборчивы в друзьях ;)   \n",
       "2   <томатик_рад> а ты не чувствуешь красоту мира?\\n<fox> честно говоря, я сейчас чувствую только отсутствие http.\\n<томатик_рад> не туда смотришь, глянь вокруг!\\n<fox> как я гляну, если http не работает? :/   \n",
       "\n",
       "                                                                                                                                                                  clear_text  \n",
       "id                                                                                                                                                                            \n",
       "1                                                                                               ppdv, все юниксы очень дружелюбны.. они просто очень разборчивы в друзьях ;)  \n",
       "2     а ты не чувствуешь красоту мира?   честно говоря, я сейчас чувствую только отсутствие http.   не туда смотришь, глянь вокруг!   как я гляну, если http не работает? :/  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextDataset\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def clear_text(text):\n",
    "    clr_text = re.sub(r\"<.*?>\", \" \", text).lower()\n",
    "    clr_text = summary = re.sub(r\"\\s\", \" \", clr_text)\n",
    "    return clr_text\n",
    "\n",
    "def build_text_files(data_json, dest_path):\n",
    "    f = open(dest_path, 'w')\n",
    "    data = ''\n",
    "    for texts in data_json:\n",
    "        summary = str(texts).strip()\n",
    "        summary = re.sub(r\"\", \"\", summary)\n",
    "        summary = re.sub(r\"<[\\w+,\\!, -]>\", \"\", summary)\n",
    "        summary = re.sub(r\"<\\w+>\", \"\", summary)\n",
    "        summary = re.sub(r\"\\s\", \" \", summary)\n",
    "        data += summary + \"  \"\n",
    "    f.write(data)\n",
    "\n",
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator\n",
    "    \n",
    "DATASET_PATH = './dataset.jsonl'\n",
    "\n",
    "with open(DATASET_PATH) as f:\n",
    "     df = pd.read_json(DATASET_PATH, lines=True).set_index('id')\n",
    "\n",
    "df.drop(['date', 'rating'], axis=1, inplace=True) # эти колонки не нужны\n",
    "df[\"clear_text\"] = df[\"text\"].apply(lambda x: clear_text(x)) # удаление тегов и лишних пробелов из текста\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df4d57f-5bb2-443a-9ab3-d0487ab353a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skwscvJlCZIR",
    "outputId": "5c6dfba1-76b4-40ab-90c9-6055b76a6a1e"
   },
   "outputs": [],
   "source": [
    "model_name = 'sberbank-ai/rugpt3small_based_on_gpt2' # Обучать будем небольшую модель, чтобы не ждать долго\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9f70eb-41c4-4c3f-a3e9-f57f7aadd472",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ys33s9JEc6t",
    "outputId": "6b9209ca-5746-4cad-c5bd-834215a90c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***\n",
      "  ладно, я в евей. пока. * ritsuko[solaris] прочел ``еврей\"\" и удивился   как ето -- пока?!(tm)\n",
      "***\n",
      "kraidiky: когда наступит апокалипсис я буду в ужасе метаться и искать где-нибудь схему газгольдера, но интернетов уже не будет! :) olegkrasnov: зачем вам схема газгольдера? alcanoid: ну надо же где-то хранить выделяемый в состоянии ужаса газ.\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sep = '\\n***\\n'\n",
    "prefix = sep.join([''] + random.sample(list(df['clear_text']), k=2) + [''])\n",
    "tokens = tokenizer(prefix, return_tensors='pt')\n",
    "tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "end_token_id = tokenizer.encode('***')[0]\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a03cda-18cb-4786-ae52-ecf23b584160",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHYfk8iLHo3R",
    "outputId": "5053c449-b5f6-4210-ed82-29c4d53c2d0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kraidiky: а что это за \"газгольдер\" на самом деле? kraidiky: Газгольдер для хранения сжиженного природного газа (СПГ).\n",
      "***\n",
      "alcanoid: А почему вы так думаете? Kraidiky: потому что СПГ - это жидкий азот.\n",
      "***\n",
      "kraidiky: у вас есть какие-то соображения по этому поводу? kraidiky: мне кажется, что с точки зрения здравого смысла эта схема должна выглядеть примерно так: http://www.gazeta.ru/politics/news/\n"
     ]
    }
   ],
   "source": [
    "size = tokens['input_ids'].shape[1]\n",
    "output = model.generate(\n",
    "    **tokens, \n",
    "    do_sample=False, \n",
    "    max_length=size+128, \n",
    "    repetition_penalty=4.2, \n",
    "    temperature=0.7,\n",
    "    num_beams=10,\n",
    ")\n",
    "decoded = tokenizer.decode(output[0])\n",
    "result = decoded[len(prefix):]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f677b066-5955-4c6f-89c7-eb5714d12081",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CN9HhOClHpFt",
    "outputId": "e35afd35-0bbb-4fd0-c129-263a58563788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 1666\n",
      "Test dataset length: 294\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df.loc[:10000, 'clear_text'],  # обрезали до 10000\n",
    "                               test_size=0.15)\n",
    "\n",
    "build_text_files(train,'./train_dataset.txt')\n",
    "build_text_files(test,'./test_dataset.txt')\n",
    "\n",
    "print(\"Train dataset length: \"+ str(len(train)))\n",
    "print(\"Test dataset length: \"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf3382b-bc79-45ff-a6c2-dc49590f0524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VH-fHrEiKHy8",
    "outputId": "c4e6153b-83ef-4aeb-bb2c-359e82105f71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_path = './train_dataset.txt'\n",
    "test_path = './test_dataset.txt'\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4866122-66a0-44a0-bb75-90fc27c97159",
   "metadata": {
    "id": "VSmxMUyOKH1v"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-train\", \n",
    "    overwrite_output_dir=True, \n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,  \n",
    "    eval_steps = 400, \n",
    "    save_steps=800, \n",
    "    warmup_steps=500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0a1f7c-8a9e-46b0-affa-897eb5c67e39",
   "metadata": {
    "id": "Bb6CQty3KH4b"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865fb292-0c74-42d0-b788-9645320ea291",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "3UjmzRzVKH7L",
    "outputId": "f064f746-eca3-4b5e-f8cc-4ca4f9111c93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 00:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=4.334056091308594, metrics={'train_runtime': 49.1347, 'train_samples_per_second': 39.015, 'train_steps_per_second': 9.769, 'total_flos': 125224206336000.0, 'train_loss': 4.334056091308594, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() # начинаем дообучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4256b69d-b1be-4554-b0d1-36cb383c453b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3E_b3udK9Ex",
    "outputId": "ea9c3d82-7c9c-4d2d-eb6e-ec0b21b0f001"
   },
   "outputs": [],
   "source": [
    "# Сохраняем обученную модель\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained('./gpt2_tokenizer_pretrained')\n",
    "model.save_pretrained('./gpt2_model_pretrained')\n",
    "\n",
    "# Загружаем обученную модель\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2_tokenizer_pretrained\")\n",
    "model_new = AutoModelForCausalLM.from_pretrained(\"./gpt2_model_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35f6763-ce45-46e8-ad39-0eca356172d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s14oMPtRK9LF",
    "outputId": "bd0e1cea-7e15-4191-df07-bbb0f8bdc52b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ritsuko[solaris] задумался о том, что может означать слово \"апокалипсис\". kraidiky: у меня есть подозрение, что это сокращение от слова \"апокалипсис\", которое можно перевести как \"погибший мир\" (в переводе на русский язык оно звучит так - \"смерть всему живому\"), а также выражение \"спасение утопающих - дело рук самих утопающих\" (в переводе на русский язык оно звучит так\n"
     ]
    }
   ],
   "source": [
    "# Проверяем генерацию текста\n",
    "size = tokens['input_ids'].shape[1]\n",
    "output = model_new.generate(\n",
    "    **tokens, \n",
    "    do_sample=False, \n",
    "    max_length=size+100, \n",
    "    repetition_penalty=5., \n",
    "    temperature=0.5,\n",
    "    num_beams=10,\n",
    ")\n",
    "decoded = tokenizer.decode(output[0])\n",
    "result = decoded[len(prefix):]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d563218-3b6c-474d-a0c4-c0b1d31aaa0f",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821650d8-a764-423f-a8d6-2d4b4b77f841",
   "metadata": {
    "id": "go66QvWSK9Nw"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1798471167.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install datasets --quiet\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !pip install corus --quiet\n",
    "# !pip install datasets --quiet\n",
    "# !wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe629b19-1475-4f91-9f43-653cccf8ae71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3t_jXeDLmAlb",
    "outputId": "2ec3a917-3ec1-4ddd-d5ce-8decf84fdbbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра 14 сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили. Вылазки гарнизона Перемышля остаются безуспешными. При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть. На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии. «Русский инвалид», 16 сентября 1914 года.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1914. Празднование столетия М.Ю. Лермонтова отложено</td>\n",
       "      <td>Министерство народного просвещения, в виду происходящих чрезвычайных событий, признало соответственным в день годовщины со дня рождения М.Ю. Лермонтова (2-го октября 1914 года) ограничиться совершением в учебных заведениях панихиды по поэту, отложив празднование юбилея до более благоприятного времени.  «Русский инвалид», 16 сентября 1914 года.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1914. Das ist Nesteroff!</td>\n",
       "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в районе Желтиева, в Галиции, летящий над нашим расположением австрийский аэроплан, собиравшийся бросить бомбы, взлетел на воздух, атаковал неприятеля и протаранил неприятельский аппарат, предотвратив жертвы в наших войсках. Сам Нестеров при этом погиб смертью героя. По словам доставленных в Киев пленных австрийских офицеров, всей неприятельской армии хорошо известно имя Нестерова. Во время воздушных разведок русских авиаторов австрийцы всегда безошибочно определяли, каким аппаратом управлял Нестеров. Когда показывался аэроплан-птица, красиво и вольно паривший в воздухе, австрийцы указывали — Das ist Nesteroff! Австрийцы боялись покойного, и все их усилия были направлены к прекращению его деятельности. За задержание отважного летчика была объявлена большая премия. Нестеров погиб в 27 лет. После Нестерова остались жена и двое детей — девочка, 5-ти лет, и мальчик, 3-х лет. Иллюстрированный журнал «Искры» № 35, сентябрь 1914 года  Песнь о Нестерове В безбрежности неба, в бескрайности ясной пустыниСражались лишь птицы и гибли лишь птицы доныне.Так птице подобный, полет свой направив могучий,Унесся пилот легкокрылый за темные тучи.А там, на земле, колыхаясь, знамена шумели, И лязгали сабли, и пушки зловеще гремели.И пламенно богу войны посылал он молитвы,И очи горели и звали и жаждали битвы…Величие духа в равнине обманчиво-зыбкой.Презрение смерти под светлою солнца улыбкой…Мольбы не напрасны. Велению рока послушный,Противник уж реет кругами в стихии воздушнойИ дрогнуло сердце. Рука, как пружина стальная,На руль налегла. Встрепенулась машина живая…Чти, родина, память героя! Решенье созрелоМгновенье – и врезался дерзко он в хрупкое тело.Пощады не знает стихия. Победа наградой…И пали противники грузной и страшной громадой…В безбрежности неба, в бескрайности ясной пустыниСражались лишь птицы и гибли лишь птицы доныне. Журнал «Нива» №37, сентябрь 1914 года</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1914. Бульдог-гонец под Льежем</td>\n",
       "      <td>Фотограф-корреспондент Daily Mirror рассказывает случай, который порадует всех друзей животных. Лейтенант бельгийской артиллерии, руководивший обороной одного из фортов Льежа, ни за что не хотел расстаться с своей собакой — бульдогом. Когда пруссаки пробрались между фортов в самый город, офицеру пришло в голову доверить бульдогу письмо, в котором он посылал успокоительную весть своим родителям. Благородный пес честно исполнил свою миссию. Десять часов спустя бульдог проник обратно в форт и принес ответ. С этого момента бульдог стал настоящим гонцом. Много раз пробирался он через линии германских войск, неся на себе спрятанными в ошейнике шифрованные депеши.Журнал «Нива» №37, сентябрь 1914 года</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
       "      <td>Лица, приехавшие в Варшаву из Люблина, передают, что туда доставлен «швабский зверь» — взятый в плен прусский майор Прейскер, бывший комендант Калиша. Это — здоровый детина, с типично прусским наглым лицом и мутными глазами. Когда этого «зверя» вели с партией пленных по улице и из толпы раздались крики и проклятия, Прейскер трусливо замешался в толпу пленных, стараясь скрыться. Зато в заключении, под конвоем наших солдат, Прейскер принял пришедшего к нему русского офицера сидя, нагло развалившись в кресле. Конвойные «помогли» ему подняться и вытянуться во фронт. Кроме Прейскера, нашими войсками взят в плен и другой «швабский зверь» — капитан Шмидт, живьем сжигавший жителей деревень, запирая их в хатах. Журнал «Нива» №38 от 20 сентября 1914 года</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      1914. Русские войска вступили в пределы Венгрии     \n",
       "1  1914. Празднование столетия М.Ю. Лермонтова отложено    \n",
       "2                               1914. Das ist Nesteroff!   \n",
       "3                        1914. Бульдог-гонец под Льежем    \n",
       "4               1914. Под Люблином пойман швабский зверь   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра 14 сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили. Вылазки гарнизона Перемышля остаются безуспешными. При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть. На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии. «Русский инвалид», 16 сентября 1914 года.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Министерство народного просвещения, в виду происходящих чрезвычайных событий, признало соответственным в день годовщины со дня рождения М.Ю. Лермонтова (2-го октября 1914 года) ограничиться совершением в учебных заведениях панихиды по поэту, отложив празднование юбилея до более благоприятного времени.  «Русский инвалид», 16 сентября 1914 года.  \n",
       "2  Штабс-капитан П. Н. Нестеров на днях, увидев в районе Желтиева, в Галиции, летящий над нашим расположением австрийский аэроплан, собиравшийся бросить бомбы, взлетел на воздух, атаковал неприятеля и протаранил неприятельский аппарат, предотвратив жертвы в наших войсках. Сам Нестеров при этом погиб смертью героя. По словам доставленных в Киев пленных австрийских офицеров, всей неприятельской армии хорошо известно имя Нестерова. Во время воздушных разведок русских авиаторов австрийцы всегда безошибочно определяли, каким аппаратом управлял Нестеров. Когда показывался аэроплан-птица, красиво и вольно паривший в воздухе, австрийцы указывали — Das ist Nesteroff! Австрийцы боялись покойного, и все их усилия были направлены к прекращению его деятельности. За задержание отважного летчика была объявлена большая премия. Нестеров погиб в 27 лет. После Нестерова остались жена и двое детей — девочка, 5-ти лет, и мальчик, 3-х лет. Иллюстрированный журнал «Искры» № 35, сентябрь 1914 года  Песнь о Нестерове В безбрежности неба, в бескрайности ясной пустыниСражались лишь птицы и гибли лишь птицы доныне.Так птице подобный, полет свой направив могучий,Унесся пилот легкокрылый за темные тучи.А там, на земле, колыхаясь, знамена шумели, И лязгали сабли, и пушки зловеще гремели.И пламенно богу войны посылал он молитвы,И очи горели и звали и жаждали битвы…Величие духа в равнине обманчиво-зыбкой.Презрение смерти под светлою солнца улыбкой…Мольбы не напрасны. Велению рока послушный,Противник уж реет кругами в стихии воздушнойИ дрогнуло сердце. Рука, как пружина стальная,На руль налегла. Встрепенулась машина живая…Чти, родина, память героя! Решенье созрелоМгновенье – и врезался дерзко он в хрупкое тело.Пощады не знает стихия. Победа наградой…И пали противники грузной и страшной громадой…В безбрежности неба, в бескрайности ясной пустыниСражались лишь птицы и гибли лишь птицы доныне. Журнал «Нива» №37, сентябрь 1914 года  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Фотограф-корреспондент Daily Mirror рассказывает случай, который порадует всех друзей животных. Лейтенант бельгийской артиллерии, руководивший обороной одного из фортов Льежа, ни за что не хотел расстаться с своей собакой — бульдогом. Когда пруссаки пробрались между фортов в самый город, офицеру пришло в голову доверить бульдогу письмо, в котором он посылал успокоительную весть своим родителям. Благородный пес честно исполнил свою миссию. Десять часов спустя бульдог проник обратно в форт и принес ответ. С этого момента бульдог стал настоящим гонцом. Много раз пробирался он через линии германских войск, неся на себе спрятанными в ошейнике шифрованные депеши.Журнал «Нива» №37, сентябрь 1914 года  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Лица, приехавшие в Варшаву из Люблина, передают, что туда доставлен «швабский зверь» — взятый в плен прусский майор Прейскер, бывший комендант Калиша. Это — здоровый детина, с типично прусским наглым лицом и мутными глазами. Когда этого «зверя» вели с партией пленных по улице и из толпы раздались крики и проклятия, Прейскер трусливо замешался в толпу пленных, стараясь скрыться. Зато в заключении, под конвоем наших солдат, Прейскер принял пришедшего к нему русского офицера сидя, нагло развалившись в кресле. Конвойные «помогли» ему подняться и вытянуться во фронт. Кроме Прейскера, нашими войсками взят в плен и другой «швабский зверь» — капитан Шмидт, живьем сжигавший жителей деревень, запирая их в хатах. Журнал «Нива» №38 от 20 сентября 1914 года  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corus import load_lenta2\n",
    "from datasets import Dataset\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "path = 'lenta-ru-news.csv.bz2'\n",
    "records = load_lenta2(path)\n",
    "# next(records)\n",
    "data = [(record.title, record.text) for record in records]\n",
    "df_news = pd.DataFrame({'title': [record[0] for record in data], 'text': [record[1] for record in data]})\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e28be2-c564-4fef-9b59-853ce1d69eb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVoOgZQtmAqk",
    "outputId": "aa858eca-51a4-4b62-fce4-450a44c66646"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800974, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950040a-0d47-409f-97af-9e9ffcb5a6b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWLmUxLZnBWk",
    "outputId": "18bf5bd2-8880-47f0-935d-901357476736"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_news[:2000], # уменьшаем датасет\n",
    "                                     test_size=0.2)\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ff396d-7f32-40bb-b226-669e5e61784f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "1d619c6fa52745b98efb17de95ffe22e",
      "8360473f4ef14b9087ca1c48f3b4fa51",
      "8a4d69e99aa74fc5af89d6c0f03697ff",
      "03a68acb667a4479a304965c04bf4f8b",
      "85b325a37213472a88f10dcb9ddb758e",
      "63ad21cb3f81469a8f6fdfc5ad0c6b46",
      "4d1719537dd24c9d9597ef01ef280f93",
      "4d3c2b5df7de4165a0052f6d9a3efd40",
      "2544de53d1f24e5d8ffccb989ef54159",
      "47d75b24815b4d4eb9d65f44cb51ede2",
      "96b265b362ea44529d631f6d0bf9ee28",
      "30fa896a7fed4dcea58edb54e22b9f31",
      "a6a93a6a3bc14a71bb003aa46b04a829",
      "20bad22d21fe4daca815b3775806f58f",
      "47bc36c121854e259246957a255fba94",
      "8ef1f87a4dd449199c7177bde63b3d2d",
      "c3837f68dc25444d9d6e821b96b62ae8",
      "def6ba8961f645638c2d2e940f67135b",
      "67e5a03c8c144809be9bfc4b9f1d9461",
      "daab6edacc514805be6e919605d52c23",
      "3e9a82a4f4094292a24428b50e5719b9",
      "4b1833fda04e462f883922d2f2f6f36b"
     ]
    },
    "id": "Sei57-9anBZZ",
    "outputId": "d2f1be21-ceae-4257-aeea-23b07c497b9f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f126c918cdb41d29fe6844093cd21c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423a4d732af8430e9acf0f722235af30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/828k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c100badb6cc347e4a229329c73d9c30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd06c2510e504910bc9639188dc243b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f43eb75b4e477e840a878107aab018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bec5e8426ad4dff855323877655bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len_txt = 400\n",
    "max_len_tlt = 50\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_input = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=max_len_txt)\n",
    "    tokenized_label = tokenizer(batch['title'], padding='max_length', truncation=True, max_length=max_len_tlt)\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "\n",
    "    return tokenized_input\n",
    "\n",
    "dataset_train = dataset_train.map(tokenize, batched=True, batch_size=8)\n",
    "dataset_test = dataset_test.map(tokenize, batched=True, batch_size=8)\n",
    "\n",
    "dataset_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dataset_test.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92affe3a-0b74-45ff-a53e-35e5f75402cb",
   "metadata": {
    "id": "bLpE6WqUnBbq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ca0ff50a3e415791e7ef532bdc4e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e566a14a25404209be64ec7d37dcae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train.save_to_disk('lenta2/train')\n",
    "dataset_test.save_to_disk('lenta2/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e1ee0c-0a47-40f0-8fee-9de446664ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUDSBGtJnBd8",
    "outputId": "369cfcae-7c2e-48ea-c3c3-0253a5b203db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa5bd3e9406474492c1a9733d25ecb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/766 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f2a25fd9b947e1bda6a0ba15b76f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/977M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c33815a5-8251-44fb-a8cd-03faa9fb93ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wimg0T2YnBgd",
    "outputId": "86fbd95a-b3a7-4f28-b384-894ca0d744c6"
   },
   "outputs": [],
   "source": [
    "output_dir = 'lenta2/output'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    save_steps=1000, \n",
    "    remove_unused_columns=True, \n",
    "    eval_steps=500, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1824dbff-01c3-4280-8f61-6539976d8b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjwr7MJ2mAxw",
    "outputId": "2c34bfa7-a58b-4c8c-89a9-8bfbc8ea8cb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 1600\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 400\n",
       " }))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = load_from_disk(\"lenta2/train\")\n",
    "dataset_test = load_from_disk(\"lenta2/test\")\n",
    "dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cd5dfa1-3ba5-4247-a3d2-a4253f579792",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GVtmIEFtmA0g",
    "outputId": "092c8133-8962-4095-a0ee-8a8fbf4845bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 14:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.556600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.358400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.6879785842895508, metrics={'train_runtime': 855.9336, 'train_samples_per_second': 9.347, 'train_steps_per_second': 4.673, 'total_flos': 4248354816000000.0, 'train_loss': 0.6879785842895508, 'epoch': 5.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a4dec93-c30b-47b8-88b2-e803ada64031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkKSi48knneb",
    "outputId": "9700b69c-e394-4d70-b9bb-b75ce5139714"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00899945-4e33-4358-8e9c-19c1df248c87",
   "metadata": {
    "id": "HAPJyC4WnnhP"
   },
   "outputs": [],
   "source": [
    "def pred(idx, model, dataset_test):\n",
    "  input_text = dataset_test['text'][idx]\n",
    "  input_title = dataset_test['title'][idx]\n",
    "\n",
    "  device = torch.device(\"cuda:0\") # (\"cuda:0\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    tokenized_text = tokenizer(input_text, \n",
    "                               truncation=True, \n",
    "                               padding=True, \n",
    "                               return_tensors='pt').to(device)\n",
    "\n",
    "    source_ids = tokenized_text['input_ids'].to(dtype = torch.long)\n",
    "    source_mask = tokenized_text['attention_mask'].to(dtype = torch.long)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids = source_ids,\n",
    "        attention_mask = source_mask, \n",
    "        max_length=512,\n",
    "        num_beams=10,\n",
    "        temperature = 1.3,\n",
    "        repetition_penalty=1, \n",
    "        length_penalty=1, \n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2\n",
    "    ).to(device)\n",
    "\n",
    "    pred = tokenizer.decode(generated_ids[0], \n",
    "                            skip_special_tokens=True, \n",
    "                            clean_up_tokenization_spaces=True)\n",
    "\n",
    "  print(\"Настоящий заголовок: \" + input_title)\n",
    "  print(\"Сгенерированный заголовок: \" + pred)\n",
    "  print(\"Текст новости: \" + input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce9ff8cd-99f1-4cd1-ac62-7818c877bc29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0-KAf1Lnnj8",
    "outputId": "a075eb65-66cf-47ce-ad03-886e5869eeae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настоящий заголовок: Рушайло: муфтий Кадыров — альтернативная фигура\n",
      "Сгенерированный заголовок: Министр внутренних дел России считает, что Кадыров может стать \"альтернативной фигурой\" при переговорах между Путином и Масхадовым\n",
      "Текст новости: Министр внутренних дел России Владимир Рушайло считает, что чеченский муфтий Ахмед Кадыров может стать \"альтернативной фигурой\" при переговорах между федеральным центром и Чечней по урегулированию ситуации в республике. Об этом он сообщил в четверг в беседе с журналистами, передает ИТАР-ТАСС. Глава МВД напомнил, что председатель правительства Владимир Путин и муфтий Кадыров встречались накануне и провели успешный диалог. Рушайло с удовлетворением отметил, что \"политический диалог уже начался\", однако он подчеркнул, что \"мы пока не делаем далеко идущих выводов\". Рушайло в очередной раз подчеркнул, что Аслан Масхадов не может представлять чеченскую сторону на переговорах. Напомним, что 11 октября Масхадов заявил, что он освобождает от должности муфтия чеченской республики Ахмеда-Хаджи Кадырова. Масхадов объяснил тогда свое решение (весьма сомнительное с точки зрения шариата) тем, что муфтий \"пытается развязать гражданскую войну в Чечне\".\n"
     ]
    }
   ],
   "source": [
    "pred(0, model=model, dataset_test=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16646ab9-3ef7-4741-820d-11948c632524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJkwIPAMnnmC",
    "outputId": "4d0de146-65ea-4801-f40a-885999538da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настоящий заголовок: Юрий Лужков: отставка Ельцина \"достаточно реальна\"\n",
      "Сгенерированный заголовок: Лужков считает, что вариант проведения выборов в России неприемлем\n",
      "Текст новости: Мэру Москвы Юрию Лужкову вероятность отставки президента и проведения в России досрочных президентских выборов кажется достаточно реальной. Как сообщает ИТАР-ТАСС, мэр заявил, что глава российского государства не может \"по состоянию здоровья эффективно выполнять свои обязанности\". В принципе, считает Лужков, вариант проведения досрочных президентских выборов вполне приемлем. Однако их совмещение по срокам с выборами в Государственную Думу недопустимо, поскольку избирателей \"нельзя лишать права сделать выбор из более широкого круга претендентов\". Вывод из игры \"неугодных кандидатов\" невозможен, отметил Юрий Лужков. Наоборот, в выборах главы государства необходимо участие всех претендентов. \"В противном случае народ не будет иметь возможности сделать полноразмерный выбор\", - добавил он. Мэр Москвы уверен: наиболее достойной кандидатурой на пост нового главы российского государства мог бы стать Евгений Примаков. В этой связи Юрий Лужков еще раз подчеркнул, что не станет выдвигать свою кандидатуру, если ему удастся уговорить Евгения Примакова сделать этот шаг.\n"
     ]
    }
   ],
   "source": [
    "pred(1, model=model, dataset_test=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dde849e7-7e6c-448b-bfb1-d06aa7cf1673",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2lK468Snnoq",
    "outputId": "dbd49126-896a-4d60-f7f9-1b5b0d9656b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настоящий заголовок: Венгерский суд постановил: Анатолий Быков будет содержаться под стражей в Будапеште\n",
      "Сгенерированный заголовок: В Венгрии арестован Анатолий Быков\n",
      "Текст новости: По вполне достоверным данным, поступившим к нам из редакции ежедневной газеты \"Время МН\", в пятницу 29 октября в Будапеште арестован красноярский предприниматель  Анатолий Быков, председатель совета директоров Красноярского алюминиевого завода (КрАЗа) и непримиримый противник губернатора Александра Лебедя. По сведениям корреспондента газеты \"Время МН\", в понедельник на судебном заседании в Будапеште (завершившемся около 20.00 по Москве) принято решение арестовать Анатолия Быкова и содержать его под стражей до предоставления российской стороной документов, подтверждающих обвинение г-на Быкова в организации заказных убийств на территории России. Подробности об истории задержания Быкова в Венгрии читайте в статье Владимира Шпака \"Добрались\" на страницах Интернет-газеты Вести.Ru и в его же специальном репортаже в завтрашнем (от 2 ноября 1999 года) выпуске ежедневной газеты \"Время МН\".\n"
     ]
    }
   ],
   "source": [
    "pred(2, model=model, dataset_test=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "691f91f5-6ee4-4711-a957-24f06e6f1bf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBHl2mTunnrF",
    "outputId": "5fd8c743-1a28-40a5-e1bc-a2e1f4fad177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настоящий заголовок: Коммунистам разрешили участвовать в выборах\n",
      "Сгенерированный заголовок: Центризбирком зарегистрировал список кандидатов в Госдуму\n",
      "Текст новости: Центризбирком РФ зарегистрировал федеральный список кандидатов в депутаты Госдумы от Компартии РФ в количестве 255 человек. За недостоверные сведения, которые были признаны существенными, из него было исключено девять человек. Среди них только актриса Елена Дропека, которая стояла под 11-м номером,представляетобщефедеральную часть списка. Претензии к первой тройке Центризбирком и другие органы неимели. Еще порядка 20 кандидатов будут подвергнутыдополнительной проверке. Среди них Валентин Чикин, ПетрРоманов, Виталий Севастьянов и другие. У 17 кандидатовнедостоверные сведения признаны носящими несущественный характер. Первая же тройка списка коммунистов выглядит следующим образом: лидер КПРФ Геннадий Зюганов, председатель Государственной Думы Геннадий Селезнев и председатель Аграрного союза Российской Федерации  Василий Стародубцев.\n"
     ]
    }
   ],
   "source": [
    "pred(3, model=model, dataset_test=dataset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
